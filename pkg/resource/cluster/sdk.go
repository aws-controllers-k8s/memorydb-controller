// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License"). You may
// not use this file except in compliance with the License. A copy of the
// License is located at
//
//     http://aws.amazon.com/apache2.0/
//
// or in the "license" file accompanying this file. This file is distributed
// on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
// express or implied. See the License for the specific language governing
// permissions and limitations under the License.

// Code generated by ack-generate. DO NOT EDIT.

package cluster

import (
	"context"
	"errors"
	"fmt"
	"math"
	"reflect"
	"strings"

	ackv1alpha1 "github.com/aws-controllers-k8s/runtime/apis/core/v1alpha1"
	ackcompare "github.com/aws-controllers-k8s/runtime/pkg/compare"
	ackcondition "github.com/aws-controllers-k8s/runtime/pkg/condition"
	ackerr "github.com/aws-controllers-k8s/runtime/pkg/errors"
	ackrequeue "github.com/aws-controllers-k8s/runtime/pkg/requeue"
	ackrtlog "github.com/aws-controllers-k8s/runtime/pkg/runtime/log"
	"github.com/aws/aws-sdk-go-v2/aws"
	svcsdk "github.com/aws/aws-sdk-go-v2/service/memorydb"
	svcsdktypes "github.com/aws/aws-sdk-go-v2/service/memorydb/types"
	smithy "github.com/aws/smithy-go"
	corev1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"

	svcapitypes "github.com/aws-controllers-k8s/memorydb-controller/apis/v1alpha1"
)

// Hack to avoid import errors during build...
var (
	_ = &metav1.Time{}
	_ = strings.ToLower("")
	_ = &svcsdk.Client{}
	_ = &svcapitypes.Cluster{}
	_ = ackv1alpha1.AWSAccountID("")
	_ = &ackerr.NotFound
	_ = &ackcondition.NotManagedMessage
	_ = &reflect.Value{}
	_ = fmt.Sprintf("")
	_ = &ackrequeue.NoRequeue{}
	_ = &aws.Config{}
)

// sdkFind returns SDK-specific information about a supplied resource
func (rm *resourceManager) sdkFind(
	ctx context.Context,
	r *resource,
) (latest *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkFind")
	defer func() {
		exit(err)
	}()
	// If any required fields in the input shape are missing, AWS resource is
	// not created yet. Return NotFound here to indicate to callers that the
	// resource isn't yet created.
	if rm.requiredFieldsMissingFromReadManyInput(r) {
		return nil, ackerr.NotFound
	}

	input, err := rm.newListRequestPayload(r)
	if err != nil {
		return nil, err
	}
	var resp *svcsdk.DescribeClustersOutput
	resp, err = rm.sdkapi.DescribeClusters(ctx, input)
	rm.metrics.RecordAPICall("READ_MANY", "DescribeClusters", err)
	if err != nil {
		var awsErr smithy.APIError
		if errors.As(err, &awsErr) && awsErr.ErrorCode() == "ClusterNotFoundFault" {
			return nil, ackerr.NotFound
		}
		return nil, err
	}

	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := r.ko.DeepCopy()

	found := false
	for _, elem := range resp.Clusters {
		if elem.ACLName != nil {
			ko.Spec.ACLName = elem.ACLName
		} else {
			ko.Spec.ACLName = nil
		}
		if elem.ARN != nil {
			if ko.Status.ACKResourceMetadata == nil {
				ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
			}
			tmpARN := ackv1alpha1.AWSResourceName(*elem.ARN)
			ko.Status.ACKResourceMetadata.ARN = &tmpARN
		}
		if elem.AutoMinorVersionUpgrade != nil {
			ko.Spec.AutoMinorVersionUpgrade = elem.AutoMinorVersionUpgrade
		} else {
			ko.Spec.AutoMinorVersionUpgrade = nil
		}
		if elem.AvailabilityMode != "" {
			ko.Status.AvailabilityMode = aws.String(string(elem.AvailabilityMode))
		} else {
			ko.Status.AvailabilityMode = nil
		}
		if elem.ClusterEndpoint != nil {
			f4 := &svcapitypes.Endpoint{}
			if elem.ClusterEndpoint.Address != nil {
				f4.Address = elem.ClusterEndpoint.Address
			}
			portCopy := int64(elem.ClusterEndpoint.Port)
			f4.Port = &portCopy
			ko.Status.ClusterEndpoint = f4
		} else {
			ko.Status.ClusterEndpoint = nil
		}
		if elem.DataTiering != "" {
			ko.Status.DataTiering = aws.String(string(elem.DataTiering))
		} else {
			ko.Status.DataTiering = nil
		}
		if elem.Description != nil {
			ko.Spec.Description = elem.Description
		} else {
			ko.Spec.Description = nil
		}
		if elem.Engine != nil {
			ko.Spec.Engine = elem.Engine
		} else {
			ko.Spec.Engine = nil
		}
		if elem.EnginePatchVersion != nil {
			ko.Status.EnginePatchVersion = elem.EnginePatchVersion
		} else {
			ko.Status.EnginePatchVersion = nil
		}
		if elem.EngineVersion != nil {
			ko.Spec.EngineVersion = elem.EngineVersion
		} else {
			ko.Spec.EngineVersion = nil
		}
		if elem.KmsKeyId != nil {
			ko.Spec.KMSKeyID = elem.KmsKeyId
		} else {
			ko.Spec.KMSKeyID = nil
		}
		if elem.MaintenanceWindow != nil {
			ko.Spec.MaintenanceWindow = elem.MaintenanceWindow
		} else {
			ko.Spec.MaintenanceWindow = nil
		}
		if elem.MultiRegionClusterName != nil {
			ko.Status.MultiRegionClusterName = elem.MultiRegionClusterName
		} else {
			ko.Status.MultiRegionClusterName = nil
		}
		if elem.Name != nil {
			ko.Spec.Name = elem.Name
		} else {
			ko.Spec.Name = nil
		}
		if elem.NodeType != nil {
			ko.Spec.NodeType = elem.NodeType
		} else {
			ko.Spec.NodeType = nil
		}
		if elem.NumberOfShards != nil {
			numberOfShardsCopy := int64(*elem.NumberOfShards)
			ko.Status.NumberOfShards = &numberOfShardsCopy
		} else {
			ko.Status.NumberOfShards = nil
		}
		if elem.ParameterGroupName != nil {
			ko.Spec.ParameterGroupName = elem.ParameterGroupName
		} else {
			ko.Spec.ParameterGroupName = nil
		}
		if elem.ParameterGroupStatus != nil {
			ko.Status.ParameterGroupStatus = elem.ParameterGroupStatus
		} else {
			ko.Status.ParameterGroupStatus = nil
		}
		if elem.PendingUpdates != nil {
			f18 := &svcapitypes.ClusterPendingUpdates{}
			if elem.PendingUpdates.ACLs != nil {
				f18f0 := &svcapitypes.ACLsUpdateStatus{}
				if elem.PendingUpdates.ACLs.ACLToApply != nil {
					f18f0.ACLToApply = elem.PendingUpdates.ACLs.ACLToApply
				}
				f18.ACLs = f18f0
			}
			if elem.PendingUpdates.Resharding != nil {
				f18f1 := &svcapitypes.ReshardingStatus{}
				if elem.PendingUpdates.Resharding.SlotMigration != nil {
					f18f1f0 := &svcapitypes.SlotMigration{}
					f18f1f0.ProgressPercentage = &elem.PendingUpdates.Resharding.SlotMigration.ProgressPercentage
					f18f1.SlotMigration = f18f1f0
				}
				f18.Resharding = f18f1
			}
			if elem.PendingUpdates.ServiceUpdates != nil {
				f18f2 := []*svcapitypes.PendingModifiedServiceUpdate{}
				for _, f18f2iter := range elem.PendingUpdates.ServiceUpdates {
					f18f2elem := &svcapitypes.PendingModifiedServiceUpdate{}
					if f18f2iter.ServiceUpdateName != nil {
						f18f2elem.ServiceUpdateName = f18f2iter.ServiceUpdateName
					}
					if f18f2iter.Status != "" {
						f18f2elem.Status = aws.String(string(f18f2iter.Status))
					}
					f18f2 = append(f18f2, f18f2elem)
				}
				f18.ServiceUpdates = f18f2
			}
			ko.Status.PendingUpdates = f18
		} else {
			ko.Status.PendingUpdates = nil
		}
		if elem.SecurityGroups != nil {
			f19 := []*svcapitypes.SecurityGroupMembership{}
			for _, f19iter := range elem.SecurityGroups {
				f19elem := &svcapitypes.SecurityGroupMembership{}
				if f19iter.SecurityGroupId != nil {
					f19elem.SecurityGroupID = f19iter.SecurityGroupId
				}
				if f19iter.Status != nil {
					f19elem.Status = f19iter.Status
				}
				f19 = append(f19, f19elem)
			}
			ko.Status.SecurityGroups = f19
		} else {
			ko.Status.SecurityGroups = nil
		}
		if elem.Shards != nil {
			f20 := []*svcapitypes.Shard{}
			for _, f20iter := range elem.Shards {
				f20elem := &svcapitypes.Shard{}
				if f20iter.Name != nil {
					f20elem.Name = f20iter.Name
				}
				if f20iter.Nodes != nil {
					f20elemf1 := []*svcapitypes.Node{}
					for _, f20elemf1iter := range f20iter.Nodes {
						f20elemf1elem := &svcapitypes.Node{}
						if f20elemf1iter.AvailabilityZone != nil {
							f20elemf1elem.AvailabilityZone = f20elemf1iter.AvailabilityZone
						}
						if f20elemf1iter.CreateTime != nil {
							f20elemf1elem.CreateTime = &metav1.Time{*f20elemf1iter.CreateTime}
						}
						if f20elemf1iter.Endpoint != nil {
							f20elemf1elemf2 := &svcapitypes.Endpoint{}
							if f20elemf1iter.Endpoint.Address != nil {
								f20elemf1elemf2.Address = f20elemf1iter.Endpoint.Address
							}
							portCopy := int64(f20elemf1iter.Endpoint.Port)
							f20elemf1elemf2.Port = &portCopy
							f20elemf1elem.Endpoint = f20elemf1elemf2
						}
						if f20elemf1iter.Name != nil {
							f20elemf1elem.Name = f20elemf1iter.Name
						}
						if f20elemf1iter.Status != nil {
							f20elemf1elem.Status = f20elemf1iter.Status
						}
						f20elemf1 = append(f20elemf1, f20elemf1elem)
					}
					f20elem.Nodes = f20elemf1
				}
				if f20iter.NumberOfNodes != nil {
					numberOfNodesCopy := int64(*f20iter.NumberOfNodes)
					f20elem.NumberOfNodes = &numberOfNodesCopy
				}
				if f20iter.Slots != nil {
					f20elem.Slots = f20iter.Slots
				}
				if f20iter.Status != nil {
					f20elem.Status = f20iter.Status
				}
				f20 = append(f20, f20elem)
			}
			ko.Status.Shards = f20
		} else {
			ko.Status.Shards = nil
		}
		if elem.SnapshotRetentionLimit != nil {
			snapshotRetentionLimitCopy := int64(*elem.SnapshotRetentionLimit)
			ko.Spec.SnapshotRetentionLimit = &snapshotRetentionLimitCopy
		} else {
			ko.Spec.SnapshotRetentionLimit = nil
		}
		if elem.SnapshotWindow != nil {
			ko.Spec.SnapshotWindow = elem.SnapshotWindow
		} else {
			ko.Spec.SnapshotWindow = nil
		}
		if elem.SnsTopicArn != nil {
			ko.Spec.SNSTopicARN = elem.SnsTopicArn
		} else {
			ko.Spec.SNSTopicARN = nil
		}
		if elem.SnsTopicStatus != nil {
			ko.Status.SNSTopicStatus = elem.SnsTopicStatus
		} else {
			ko.Status.SNSTopicStatus = nil
		}
		if elem.Status != nil {
			ko.Status.Status = elem.Status
		} else {
			ko.Status.Status = nil
		}
		if elem.SubnetGroupName != nil {
			ko.Spec.SubnetGroupName = elem.SubnetGroupName
		} else {
			ko.Spec.SubnetGroupName = nil
		}
		if elem.TLSEnabled != nil {
			ko.Spec.TLSEnabled = elem.TLSEnabled
		} else {
			ko.Spec.TLSEnabled = nil
		}
		found = true
		break
	}
	if !found {
		return nil, ackerr.NotFound
	}

	rm.setStatusDefaults(ko)
	cluster := resp.Clusters[0]
	if cluster.NumberOfShards != nil {
		ko.Spec.NumShards = aws.Int64(int64(*cluster.NumberOfShards))
	} else {
		ko.Spec.NumShards = nil
	}

	if cluster.Shards != nil && cluster.Shards[0].NumberOfNodes != nil {
		replicas := *cluster.Shards[0].NumberOfNodes - 1
		ko.Spec.NumReplicasPerShard = aws.Int64(int64(replicas))
	} else {
		ko.Spec.NumReplicasPerShard = nil
	}

	if cluster.SecurityGroups != nil {
		var securityGroupIds []*string
		for _, securityGroup := range cluster.SecurityGroups {
			if securityGroup.SecurityGroupId != nil {
				securityGroupIds = append(securityGroupIds, securityGroup.SecurityGroupId)
			}
		}
		ko.Spec.SecurityGroupIDs = securityGroupIds
	} else {
		ko.Spec.SecurityGroupIDs = nil
	}

	respErr := rm.setAllowedNodeTypeUpdates(ctx, ko)
	if respErr != nil {
		return nil, respErr
	}

	ko.Status.Events, err = rm.getEvents(ctx, r)
	if err != nil {
		return nil, err
	}

	if rm.isClusterAvailable(&resource{ko}) {
		resourceARN := (*string)(ko.Status.ACKResourceMetadata.ARN)
		tags, err := rm.getTags(ctx, *resourceARN)
		if err != nil {
			return nil, err
		}
		ko.Spec.Tags = tags
	}

	return &resource{ko}, nil
}

// requiredFieldsMissingFromReadManyInput returns true if there are any fields
// for the ReadMany Input shape that are required but not present in the
// resource's Spec or Status
func (rm *resourceManager) requiredFieldsMissingFromReadManyInput(
	r *resource,
) bool {
	return r.ko.Spec.Name == nil

}

// newListRequestPayload returns SDK-specific struct for the HTTP request
// payload of the List API call for the resource
func (rm *resourceManager) newListRequestPayload(
	r *resource,
) (*svcsdk.DescribeClustersInput, error) {
	res := &svcsdk.DescribeClustersInput{}

	if r.ko.Spec.Name != nil {
		res.ClusterName = r.ko.Spec.Name
	}
	res.ShowShardDetails = aws.Bool(true)

	return res, nil
}

// sdkCreate creates the supplied resource in the backend AWS service API and
// returns a copy of the resource with resource fields (in both Spec and
// Status) filled in with values from the CREATE API operation's Output shape.
func (rm *resourceManager) sdkCreate(
	ctx context.Context,
	desired *resource,
) (created *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkCreate")
	defer func() {
		exit(err)
	}()
	input, err := rm.newCreateRequestPayload(ctx, desired)
	if err != nil {
		return nil, err
	}

	var resp *svcsdk.CreateClusterOutput
	_ = resp
	resp, err = rm.sdkapi.CreateCluster(ctx, input)
	rm.metrics.RecordAPICall("CREATE", "CreateCluster", err)
	if err != nil {
		return nil, err
	}
	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := desired.ko.DeepCopy()

	if resp.Cluster.ACLName != nil {
		ko.Spec.ACLName = resp.Cluster.ACLName
	} else {
		ko.Spec.ACLName = nil
	}
	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if resp.Cluster.ARN != nil {
		arn := ackv1alpha1.AWSResourceName(*resp.Cluster.ARN)
		ko.Status.ACKResourceMetadata.ARN = &arn
	}
	if resp.Cluster.AutoMinorVersionUpgrade != nil {
		ko.Spec.AutoMinorVersionUpgrade = resp.Cluster.AutoMinorVersionUpgrade
	} else {
		ko.Spec.AutoMinorVersionUpgrade = nil
	}
	if resp.Cluster.AvailabilityMode != "" {
		ko.Status.AvailabilityMode = aws.String(string(resp.Cluster.AvailabilityMode))
	} else {
		ko.Status.AvailabilityMode = nil
	}
	if resp.Cluster.ClusterEndpoint != nil {
		f4 := &svcapitypes.Endpoint{}
		if resp.Cluster.ClusterEndpoint.Address != nil {
			f4.Address = resp.Cluster.ClusterEndpoint.Address
		}
		portCopy := int64(resp.Cluster.ClusterEndpoint.Port)
		f4.Port = &portCopy
		ko.Status.ClusterEndpoint = f4
	} else {
		ko.Status.ClusterEndpoint = nil
	}
	if resp.Cluster.DataTiering != "" {
		ko.Status.DataTiering = aws.String(string(resp.Cluster.DataTiering))
	} else {
		ko.Status.DataTiering = nil
	}
	if resp.Cluster.Description != nil {
		ko.Spec.Description = resp.Cluster.Description
	} else {
		ko.Spec.Description = nil
	}
	if resp.Cluster.Engine != nil {
		ko.Spec.Engine = resp.Cluster.Engine
	} else {
		ko.Spec.Engine = nil
	}
	if resp.Cluster.EnginePatchVersion != nil {
		ko.Status.EnginePatchVersion = resp.Cluster.EnginePatchVersion
	} else {
		ko.Status.EnginePatchVersion = nil
	}
	if resp.Cluster.EngineVersion != nil {
		ko.Spec.EngineVersion = resp.Cluster.EngineVersion
	} else {
		ko.Spec.EngineVersion = nil
	}
	if resp.Cluster.KmsKeyId != nil {
		ko.Spec.KMSKeyID = resp.Cluster.KmsKeyId
	} else {
		ko.Spec.KMSKeyID = nil
	}
	if resp.Cluster.MaintenanceWindow != nil {
		ko.Spec.MaintenanceWindow = resp.Cluster.MaintenanceWindow
	} else {
		ko.Spec.MaintenanceWindow = nil
	}
	if resp.Cluster.MultiRegionClusterName != nil {
		ko.Status.MultiRegionClusterName = resp.Cluster.MultiRegionClusterName
	} else {
		ko.Status.MultiRegionClusterName = nil
	}
	if resp.Cluster.Name != nil {
		ko.Spec.Name = resp.Cluster.Name
	} else {
		ko.Spec.Name = nil
	}
	if resp.Cluster.NodeType != nil {
		ko.Spec.NodeType = resp.Cluster.NodeType
	} else {
		ko.Spec.NodeType = nil
	}
	if resp.Cluster.NumberOfShards != nil {
		numberOfShardsCopy := int64(*resp.Cluster.NumberOfShards)
		ko.Status.NumberOfShards = &numberOfShardsCopy
	} else {
		ko.Status.NumberOfShards = nil
	}
	if resp.Cluster.ParameterGroupName != nil {
		ko.Spec.ParameterGroupName = resp.Cluster.ParameterGroupName
	} else {
		ko.Spec.ParameterGroupName = nil
	}
	if resp.Cluster.ParameterGroupStatus != nil {
		ko.Status.ParameterGroupStatus = resp.Cluster.ParameterGroupStatus
	} else {
		ko.Status.ParameterGroupStatus = nil
	}
	if resp.Cluster.PendingUpdates != nil {
		f18 := &svcapitypes.ClusterPendingUpdates{}
		if resp.Cluster.PendingUpdates.ACLs != nil {
			f18f0 := &svcapitypes.ACLsUpdateStatus{}
			if resp.Cluster.PendingUpdates.ACLs.ACLToApply != nil {
				f18f0.ACLToApply = resp.Cluster.PendingUpdates.ACLs.ACLToApply
			}
			f18.ACLs = f18f0
		}
		if resp.Cluster.PendingUpdates.Resharding != nil {
			f18f1 := &svcapitypes.ReshardingStatus{}
			if resp.Cluster.PendingUpdates.Resharding.SlotMigration != nil {
				f18f1f0 := &svcapitypes.SlotMigration{}
				f18f1f0.ProgressPercentage = &resp.Cluster.PendingUpdates.Resharding.SlotMigration.ProgressPercentage
				f18f1.SlotMigration = f18f1f0
			}
			f18.Resharding = f18f1
		}
		if resp.Cluster.PendingUpdates.ServiceUpdates != nil {
			f18f2 := []*svcapitypes.PendingModifiedServiceUpdate{}
			for _, f18f2iter := range resp.Cluster.PendingUpdates.ServiceUpdates {
				f18f2elem := &svcapitypes.PendingModifiedServiceUpdate{}
				if f18f2iter.ServiceUpdateName != nil {
					f18f2elem.ServiceUpdateName = f18f2iter.ServiceUpdateName
				}
				if f18f2iter.Status != "" {
					f18f2elem.Status = aws.String(string(f18f2iter.Status))
				}
				f18f2 = append(f18f2, f18f2elem)
			}
			f18.ServiceUpdates = f18f2
		}
		ko.Status.PendingUpdates = f18
	} else {
		ko.Status.PendingUpdates = nil
	}
	if resp.Cluster.SecurityGroups != nil {
		f19 := []*svcapitypes.SecurityGroupMembership{}
		for _, f19iter := range resp.Cluster.SecurityGroups {
			f19elem := &svcapitypes.SecurityGroupMembership{}
			if f19iter.SecurityGroupId != nil {
				f19elem.SecurityGroupID = f19iter.SecurityGroupId
			}
			if f19iter.Status != nil {
				f19elem.Status = f19iter.Status
			}
			f19 = append(f19, f19elem)
		}
		ko.Status.SecurityGroups = f19
	} else {
		ko.Status.SecurityGroups = nil
	}
	if resp.Cluster.Shards != nil {
		f20 := []*svcapitypes.Shard{}
		for _, f20iter := range resp.Cluster.Shards {
			f20elem := &svcapitypes.Shard{}
			if f20iter.Name != nil {
				f20elem.Name = f20iter.Name
			}
			if f20iter.Nodes != nil {
				f20elemf1 := []*svcapitypes.Node{}
				for _, f20elemf1iter := range f20iter.Nodes {
					f20elemf1elem := &svcapitypes.Node{}
					if f20elemf1iter.AvailabilityZone != nil {
						f20elemf1elem.AvailabilityZone = f20elemf1iter.AvailabilityZone
					}
					if f20elemf1iter.CreateTime != nil {
						f20elemf1elem.CreateTime = &metav1.Time{*f20elemf1iter.CreateTime}
					}
					if f20elemf1iter.Endpoint != nil {
						f20elemf1elemf2 := &svcapitypes.Endpoint{}
						if f20elemf1iter.Endpoint.Address != nil {
							f20elemf1elemf2.Address = f20elemf1iter.Endpoint.Address
						}
						portCopy := int64(f20elemf1iter.Endpoint.Port)
						f20elemf1elemf2.Port = &portCopy
						f20elemf1elem.Endpoint = f20elemf1elemf2
					}
					if f20elemf1iter.Name != nil {
						f20elemf1elem.Name = f20elemf1iter.Name
					}
					if f20elemf1iter.Status != nil {
						f20elemf1elem.Status = f20elemf1iter.Status
					}
					f20elemf1 = append(f20elemf1, f20elemf1elem)
				}
				f20elem.Nodes = f20elemf1
			}
			if f20iter.NumberOfNodes != nil {
				numberOfNodesCopy := int64(*f20iter.NumberOfNodes)
				f20elem.NumberOfNodes = &numberOfNodesCopy
			}
			if f20iter.Slots != nil {
				f20elem.Slots = f20iter.Slots
			}
			if f20iter.Status != nil {
				f20elem.Status = f20iter.Status
			}
			f20 = append(f20, f20elem)
		}
		ko.Status.Shards = f20
	} else {
		ko.Status.Shards = nil
	}
	if resp.Cluster.SnapshotRetentionLimit != nil {
		snapshotRetentionLimitCopy := int64(*resp.Cluster.SnapshotRetentionLimit)
		ko.Spec.SnapshotRetentionLimit = &snapshotRetentionLimitCopy
	} else {
		ko.Spec.SnapshotRetentionLimit = nil
	}
	if resp.Cluster.SnapshotWindow != nil {
		ko.Spec.SnapshotWindow = resp.Cluster.SnapshotWindow
	} else {
		ko.Spec.SnapshotWindow = nil
	}
	if resp.Cluster.SnsTopicArn != nil {
		ko.Spec.SNSTopicARN = resp.Cluster.SnsTopicArn
	} else {
		ko.Spec.SNSTopicARN = nil
	}
	if resp.Cluster.SnsTopicStatus != nil {
		ko.Status.SNSTopicStatus = resp.Cluster.SnsTopicStatus
	} else {
		ko.Status.SNSTopicStatus = nil
	}
	if resp.Cluster.Status != nil {
		ko.Status.Status = resp.Cluster.Status
	} else {
		ko.Status.Status = nil
	}
	if resp.Cluster.SubnetGroupName != nil {
		ko.Spec.SubnetGroupName = resp.Cluster.SubnetGroupName
	} else {
		ko.Spec.SubnetGroupName = nil
	}
	if resp.Cluster.TLSEnabled != nil {
		ko.Spec.TLSEnabled = resp.Cluster.TLSEnabled
	} else {
		ko.Spec.TLSEnabled = nil
	}

	rm.setStatusDefaults(ko)
	ko, err = rm.setShardDetails(ctx, desired, ko)

	if err != nil {
		return nil, err
	}

	// Update the annotations to handle async rollback
	rm.setNodeTypeAnnotation(input.NodeType, ko)
	if input.NumReplicasPerShard != nil {
		rm.setNumReplicasPerShardAnnotation(int64(*input.NumReplicasPerShard), ko)
	}

	if input.NumShards != nil {
		rm.setNumShardAnnotation(int64(*input.NumShards), ko)
	}
	return &resource{ko}, nil
}

// newCreateRequestPayload returns an SDK-specific struct for the HTTP request
// payload of the Create API call for the resource
func (rm *resourceManager) newCreateRequestPayload(
	ctx context.Context,
	r *resource,
) (*svcsdk.CreateClusterInput, error) {
	res := &svcsdk.CreateClusterInput{}

	if r.ko.Spec.ACLName != nil {
		res.ACLName = r.ko.Spec.ACLName
	}
	if r.ko.Spec.AutoMinorVersionUpgrade != nil {
		res.AutoMinorVersionUpgrade = r.ko.Spec.AutoMinorVersionUpgrade
	}
	if r.ko.Spec.Name != nil {
		res.ClusterName = r.ko.Spec.Name
	}
	if r.ko.Spec.Description != nil {
		res.Description = r.ko.Spec.Description
	}
	if r.ko.Spec.Engine != nil {
		res.Engine = r.ko.Spec.Engine
	}
	if r.ko.Spec.EngineVersion != nil {
		res.EngineVersion = r.ko.Spec.EngineVersion
	}
	if r.ko.Spec.KMSKeyID != nil {
		res.KmsKeyId = r.ko.Spec.KMSKeyID
	}
	if r.ko.Spec.MaintenanceWindow != nil {
		res.MaintenanceWindow = r.ko.Spec.MaintenanceWindow
	}
	if r.ko.Spec.NodeType != nil {
		res.NodeType = r.ko.Spec.NodeType
	}
	if r.ko.Spec.NumReplicasPerShard != nil {
		numReplicasPerShardCopy0 := *r.ko.Spec.NumReplicasPerShard
		if numReplicasPerShardCopy0 > math.MaxInt32 || numReplicasPerShardCopy0 < math.MinInt32 {
			return nil, fmt.Errorf("error: field NumReplicasPerShard is of type int32")
		}
		numReplicasPerShardCopy := int32(numReplicasPerShardCopy0)
		res.NumReplicasPerShard = &numReplicasPerShardCopy
	}
	if r.ko.Spec.NumShards != nil {
		numShardsCopy0 := *r.ko.Spec.NumShards
		if numShardsCopy0 > math.MaxInt32 || numShardsCopy0 < math.MinInt32 {
			return nil, fmt.Errorf("error: field NumShards is of type int32")
		}
		numShardsCopy := int32(numShardsCopy0)
		res.NumShards = &numShardsCopy
	}
	if r.ko.Spec.ParameterGroupName != nil {
		res.ParameterGroupName = r.ko.Spec.ParameterGroupName
	}
	if r.ko.Spec.Port != nil {
		portCopy0 := *r.ko.Spec.Port
		if portCopy0 > math.MaxInt32 || portCopy0 < math.MinInt32 {
			return nil, fmt.Errorf("error: field Port is of type int32")
		}
		portCopy := int32(portCopy0)
		res.Port = &portCopy
	}
	if r.ko.Spec.SecurityGroupIDs != nil {
		res.SecurityGroupIds = aws.ToStringSlice(r.ko.Spec.SecurityGroupIDs)
	}
	if r.ko.Spec.SnapshotARNs != nil {
		res.SnapshotArns = aws.ToStringSlice(r.ko.Spec.SnapshotARNs)
	}
	if r.ko.Spec.SnapshotName != nil {
		res.SnapshotName = r.ko.Spec.SnapshotName
	}
	if r.ko.Spec.SnapshotRetentionLimit != nil {
		snapshotRetentionLimitCopy0 := *r.ko.Spec.SnapshotRetentionLimit
		if snapshotRetentionLimitCopy0 > math.MaxInt32 || snapshotRetentionLimitCopy0 < math.MinInt32 {
			return nil, fmt.Errorf("error: field SnapshotRetentionLimit is of type int32")
		}
		snapshotRetentionLimitCopy := int32(snapshotRetentionLimitCopy0)
		res.SnapshotRetentionLimit = &snapshotRetentionLimitCopy
	}
	if r.ko.Spec.SnapshotWindow != nil {
		res.SnapshotWindow = r.ko.Spec.SnapshotWindow
	}
	if r.ko.Spec.SNSTopicARN != nil {
		res.SnsTopicArn = r.ko.Spec.SNSTopicARN
	}
	if r.ko.Spec.SubnetGroupName != nil {
		res.SubnetGroupName = r.ko.Spec.SubnetGroupName
	}
	if r.ko.Spec.TLSEnabled != nil {
		res.TLSEnabled = r.ko.Spec.TLSEnabled
	}
	if r.ko.Spec.Tags != nil {
		f21 := []svcsdktypes.Tag{}
		for _, f21iter := range r.ko.Spec.Tags {
			f21elem := &svcsdktypes.Tag{}
			if f21iter.Key != nil {
				f21elem.Key = f21iter.Key
			}
			if f21iter.Value != nil {
				f21elem.Value = f21iter.Value
			}
			f21 = append(f21, *f21elem)
		}
		res.Tags = f21
	}

	return res, nil
}

// sdkUpdate patches the supplied resource in the backend AWS service API and
// returns a new resource with updated fields.
func (rm *resourceManager) sdkUpdate(
	ctx context.Context,
	desired *resource,
	latest *resource,
	delta *ackcompare.Delta,
) (updated *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkUpdate")
	defer func() {
		exit(err)
	}()
	res, err := rm.validateClusterNeedsUpdate(desired, latest, delta)

	if err != nil || res != nil {
		return res, err
	}

	if delta.DifferentAt("Spec.Tags") {
		err = rm.updateTags(ctx, desired, latest)
		if err != nil {
			return nil, err
		}
	}

	if !delta.DifferentExcept("Spec.Tags") {
		return desired, nil
	}

	input, err := rm.newUpdateRequestPayload(ctx, desired, delta)
	if err != nil {
		return nil, err
	}
	input = rm.newMemoryDBClusterUploadPayload(desired, latest, delta)

	var resp *svcsdk.UpdateClusterOutput
	_ = resp
	resp, err = rm.sdkapi.UpdateCluster(ctx, input)
	rm.metrics.RecordAPICall("UPDATE", "UpdateCluster", err)
	if err != nil {
		return nil, err
	}
	// Merge in the information we read from the API call above to the copy of
	// the original Kubernetes object we passed to the function
	ko := desired.ko.DeepCopy()

	if resp.Cluster.ACLName != nil {
		ko.Spec.ACLName = resp.Cluster.ACLName
	} else {
		ko.Spec.ACLName = nil
	}
	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if resp.Cluster.ARN != nil {
		arn := ackv1alpha1.AWSResourceName(*resp.Cluster.ARN)
		ko.Status.ACKResourceMetadata.ARN = &arn
	}
	if resp.Cluster.AutoMinorVersionUpgrade != nil {
		ko.Spec.AutoMinorVersionUpgrade = resp.Cluster.AutoMinorVersionUpgrade
	} else {
		ko.Spec.AutoMinorVersionUpgrade = nil
	}
	if resp.Cluster.AvailabilityMode != "" {
		ko.Status.AvailabilityMode = aws.String(string(resp.Cluster.AvailabilityMode))
	} else {
		ko.Status.AvailabilityMode = nil
	}
	if resp.Cluster.ClusterEndpoint != nil {
		f4 := &svcapitypes.Endpoint{}
		if resp.Cluster.ClusterEndpoint.Address != nil {
			f4.Address = resp.Cluster.ClusterEndpoint.Address
		}
		portCopy := int64(resp.Cluster.ClusterEndpoint.Port)
		f4.Port = &portCopy
		ko.Status.ClusterEndpoint = f4
	} else {
		ko.Status.ClusterEndpoint = nil
	}
	if resp.Cluster.DataTiering != "" {
		ko.Status.DataTiering = aws.String(string(resp.Cluster.DataTiering))
	} else {
		ko.Status.DataTiering = nil
	}
	if resp.Cluster.Description != nil {
		ko.Spec.Description = resp.Cluster.Description
	} else {
		ko.Spec.Description = nil
	}
	if resp.Cluster.Engine != nil {
		ko.Spec.Engine = resp.Cluster.Engine
	} else {
		ko.Spec.Engine = nil
	}
	if resp.Cluster.EnginePatchVersion != nil {
		ko.Status.EnginePatchVersion = resp.Cluster.EnginePatchVersion
	} else {
		ko.Status.EnginePatchVersion = nil
	}
	if resp.Cluster.EngineVersion != nil {
		ko.Spec.EngineVersion = resp.Cluster.EngineVersion
	} else {
		ko.Spec.EngineVersion = nil
	}
	if resp.Cluster.KmsKeyId != nil {
		ko.Spec.KMSKeyID = resp.Cluster.KmsKeyId
	} else {
		ko.Spec.KMSKeyID = nil
	}
	if resp.Cluster.MaintenanceWindow != nil {
		ko.Spec.MaintenanceWindow = resp.Cluster.MaintenanceWindow
	} else {
		ko.Spec.MaintenanceWindow = nil
	}
	if resp.Cluster.MultiRegionClusterName != nil {
		ko.Status.MultiRegionClusterName = resp.Cluster.MultiRegionClusterName
	} else {
		ko.Status.MultiRegionClusterName = nil
	}
	if resp.Cluster.Name != nil {
		ko.Spec.Name = resp.Cluster.Name
	} else {
		ko.Spec.Name = nil
	}
	if resp.Cluster.NodeType != nil {
		ko.Spec.NodeType = resp.Cluster.NodeType
	} else {
		ko.Spec.NodeType = nil
	}
	if resp.Cluster.NumberOfShards != nil {
		numberOfShardsCopy := int64(*resp.Cluster.NumberOfShards)
		ko.Status.NumberOfShards = &numberOfShardsCopy
	} else {
		ko.Status.NumberOfShards = nil
	}
	if resp.Cluster.ParameterGroupName != nil {
		ko.Spec.ParameterGroupName = resp.Cluster.ParameterGroupName
	} else {
		ko.Spec.ParameterGroupName = nil
	}
	if resp.Cluster.ParameterGroupStatus != nil {
		ko.Status.ParameterGroupStatus = resp.Cluster.ParameterGroupStatus
	} else {
		ko.Status.ParameterGroupStatus = nil
	}
	if resp.Cluster.PendingUpdates != nil {
		f18 := &svcapitypes.ClusterPendingUpdates{}
		if resp.Cluster.PendingUpdates.ACLs != nil {
			f18f0 := &svcapitypes.ACLsUpdateStatus{}
			if resp.Cluster.PendingUpdates.ACLs.ACLToApply != nil {
				f18f0.ACLToApply = resp.Cluster.PendingUpdates.ACLs.ACLToApply
			}
			f18.ACLs = f18f0
		}
		if resp.Cluster.PendingUpdates.Resharding != nil {
			f18f1 := &svcapitypes.ReshardingStatus{}
			if resp.Cluster.PendingUpdates.Resharding.SlotMigration != nil {
				f18f1f0 := &svcapitypes.SlotMigration{}
				f18f1f0.ProgressPercentage = &resp.Cluster.PendingUpdates.Resharding.SlotMigration.ProgressPercentage
				f18f1.SlotMigration = f18f1f0
			}
			f18.Resharding = f18f1
		}
		if resp.Cluster.PendingUpdates.ServiceUpdates != nil {
			f18f2 := []*svcapitypes.PendingModifiedServiceUpdate{}
			for _, f18f2iter := range resp.Cluster.PendingUpdates.ServiceUpdates {
				f18f2elem := &svcapitypes.PendingModifiedServiceUpdate{}
				if f18f2iter.ServiceUpdateName != nil {
					f18f2elem.ServiceUpdateName = f18f2iter.ServiceUpdateName
				}
				if f18f2iter.Status != "" {
					f18f2elem.Status = aws.String(string(f18f2iter.Status))
				}
				f18f2 = append(f18f2, f18f2elem)
			}
			f18.ServiceUpdates = f18f2
		}
		ko.Status.PendingUpdates = f18
	} else {
		ko.Status.PendingUpdates = nil
	}
	if resp.Cluster.SecurityGroups != nil {
		f19 := []*svcapitypes.SecurityGroupMembership{}
		for _, f19iter := range resp.Cluster.SecurityGroups {
			f19elem := &svcapitypes.SecurityGroupMembership{}
			if f19iter.SecurityGroupId != nil {
				f19elem.SecurityGroupID = f19iter.SecurityGroupId
			}
			if f19iter.Status != nil {
				f19elem.Status = f19iter.Status
			}
			f19 = append(f19, f19elem)
		}
		ko.Status.SecurityGroups = f19
	} else {
		ko.Status.SecurityGroups = nil
	}
	if resp.Cluster.Shards != nil {
		f20 := []*svcapitypes.Shard{}
		for _, f20iter := range resp.Cluster.Shards {
			f20elem := &svcapitypes.Shard{}
			if f20iter.Name != nil {
				f20elem.Name = f20iter.Name
			}
			if f20iter.Nodes != nil {
				f20elemf1 := []*svcapitypes.Node{}
				for _, f20elemf1iter := range f20iter.Nodes {
					f20elemf1elem := &svcapitypes.Node{}
					if f20elemf1iter.AvailabilityZone != nil {
						f20elemf1elem.AvailabilityZone = f20elemf1iter.AvailabilityZone
					}
					if f20elemf1iter.CreateTime != nil {
						f20elemf1elem.CreateTime = &metav1.Time{*f20elemf1iter.CreateTime}
					}
					if f20elemf1iter.Endpoint != nil {
						f20elemf1elemf2 := &svcapitypes.Endpoint{}
						if f20elemf1iter.Endpoint.Address != nil {
							f20elemf1elemf2.Address = f20elemf1iter.Endpoint.Address
						}
						portCopy := int64(f20elemf1iter.Endpoint.Port)
						f20elemf1elemf2.Port = &portCopy
						f20elemf1elem.Endpoint = f20elemf1elemf2
					}
					if f20elemf1iter.Name != nil {
						f20elemf1elem.Name = f20elemf1iter.Name
					}
					if f20elemf1iter.Status != nil {
						f20elemf1elem.Status = f20elemf1iter.Status
					}
					f20elemf1 = append(f20elemf1, f20elemf1elem)
				}
				f20elem.Nodes = f20elemf1
			}
			if f20iter.NumberOfNodes != nil {
				numberOfNodesCopy := int64(*f20iter.NumberOfNodes)
				f20elem.NumberOfNodes = &numberOfNodesCopy
			}
			if f20iter.Slots != nil {
				f20elem.Slots = f20iter.Slots
			}
			if f20iter.Status != nil {
				f20elem.Status = f20iter.Status
			}
			f20 = append(f20, f20elem)
		}
		ko.Status.Shards = f20
	} else {
		ko.Status.Shards = nil
	}
	if resp.Cluster.SnapshotRetentionLimit != nil {
		snapshotRetentionLimitCopy := int64(*resp.Cluster.SnapshotRetentionLimit)
		ko.Spec.SnapshotRetentionLimit = &snapshotRetentionLimitCopy
	} else {
		ko.Spec.SnapshotRetentionLimit = nil
	}
	if resp.Cluster.SnapshotWindow != nil {
		ko.Spec.SnapshotWindow = resp.Cluster.SnapshotWindow
	} else {
		ko.Spec.SnapshotWindow = nil
	}
	if resp.Cluster.SnsTopicArn != nil {
		ko.Spec.SNSTopicARN = resp.Cluster.SnsTopicArn
	} else {
		ko.Spec.SNSTopicARN = nil
	}
	if resp.Cluster.SnsTopicStatus != nil {
		ko.Status.SNSTopicStatus = resp.Cluster.SnsTopicStatus
	} else {
		ko.Status.SNSTopicStatus = nil
	}
	if resp.Cluster.Status != nil {
		ko.Status.Status = resp.Cluster.Status
	} else {
		ko.Status.Status = nil
	}
	if resp.Cluster.SubnetGroupName != nil {
		ko.Spec.SubnetGroupName = resp.Cluster.SubnetGroupName
	} else {
		ko.Spec.SubnetGroupName = nil
	}
	if resp.Cluster.TLSEnabled != nil {
		ko.Spec.TLSEnabled = resp.Cluster.TLSEnabled
	} else {
		ko.Spec.TLSEnabled = nil
	}

	rm.setStatusDefaults(ko)
	ko, err = rm.setShardDetails(ctx, desired, ko)

	if err != nil {
		return nil, err
	}

	// Do not perform spec patching as these fields eventually get updated
	ko.Spec.NumShards = desired.ko.Spec.NumShards
	ko.Spec.NumReplicasPerShard = desired.ko.Spec.NumReplicasPerShard
	ko.Spec.ACLName = desired.ko.Spec.ACLName
	ko.Spec.NodeType = desired.ko.Spec.NodeType
	ko.Spec.EngineVersion = desired.ko.Spec.EngineVersion

	// Update the annotations to handle async rollback
	rm.setNodeTypeAnnotation(input.NodeType, ko)
	if input.ReplicaConfiguration != nil {
		rm.setNumReplicasPerShardAnnotation(int64(input.ReplicaConfiguration.ReplicaCount), ko)
	}
	if input.ShardConfiguration != nil {
		rm.setNumShardAnnotation(int64(input.ShardConfiguration.ShardCount), ko)
	}
	return &resource{ko}, requeueWaitWhileUpdating

	return &resource{ko}, nil
}

// newUpdateRequestPayload returns an SDK-specific struct for the HTTP request
// payload of the Update API call for the resource
func (rm *resourceManager) newUpdateRequestPayload(
	ctx context.Context,
	r *resource,
	delta *ackcompare.Delta,
) (*svcsdk.UpdateClusterInput, error) {
	res := &svcsdk.UpdateClusterInput{}

	if r.ko.Spec.ACLName != nil {
		res.ACLName = r.ko.Spec.ACLName
	}
	if r.ko.Spec.Name != nil {
		res.ClusterName = r.ko.Spec.Name
	}
	if r.ko.Spec.Description != nil {
		res.Description = r.ko.Spec.Description
	}
	if r.ko.Spec.Engine != nil {
		res.Engine = r.ko.Spec.Engine
	}
	if r.ko.Spec.EngineVersion != nil {
		res.EngineVersion = r.ko.Spec.EngineVersion
	}
	if r.ko.Spec.MaintenanceWindow != nil {
		res.MaintenanceWindow = r.ko.Spec.MaintenanceWindow
	}
	if r.ko.Spec.NodeType != nil {
		res.NodeType = r.ko.Spec.NodeType
	}
	if r.ko.Spec.ParameterGroupName != nil {
		res.ParameterGroupName = r.ko.Spec.ParameterGroupName
	}
	if r.ko.Spec.SecurityGroupIDs != nil {
		res.SecurityGroupIds = aws.ToStringSlice(r.ko.Spec.SecurityGroupIDs)
	}
	if r.ko.Spec.SnapshotRetentionLimit != nil {
		snapshotRetentionLimitCopy0 := *r.ko.Spec.SnapshotRetentionLimit
		if snapshotRetentionLimitCopy0 > math.MaxInt32 || snapshotRetentionLimitCopy0 < math.MinInt32 {
			return nil, fmt.Errorf("error: field SnapshotRetentionLimit is of type int32")
		}
		snapshotRetentionLimitCopy := int32(snapshotRetentionLimitCopy0)
		res.SnapshotRetentionLimit = &snapshotRetentionLimitCopy
	}
	if r.ko.Spec.SnapshotWindow != nil {
		res.SnapshotWindow = r.ko.Spec.SnapshotWindow
	}
	if r.ko.Spec.SNSTopicARN != nil {
		res.SnsTopicArn = r.ko.Spec.SNSTopicARN
	}
	if r.ko.Status.SNSTopicStatus != nil {
		res.SnsTopicStatus = r.ko.Status.SNSTopicStatus
	}

	return res, nil
}

// sdkDelete deletes the supplied resource in the backend AWS service API
func (rm *resourceManager) sdkDelete(
	ctx context.Context,
	r *resource,
) (latest *resource, err error) {
	rlog := ackrtlog.FromContext(ctx)
	exit := rlog.Trace("rm.sdkDelete")
	defer func() {
		exit(err)
	}()
	if isDeleting(r) {
		// Setting resource synced condition to false will trigger a requeue of
		// the resource.
		ackcondition.SetSynced(
			r,
			corev1.ConditionFalse,
			&condMsgCurrentlyDeleting,
			nil,
		)
		// Need to return a requeue error here, otherwise:
		// - reconciler.deleteResource() marks the resource unmanaged
		// - reconciler.HandleReconcileError() does not update status for unmanaged resource
		// - reconciler.handleRequeues() is not invoked for delete code path.
		// TODO: return err as nil when reconciler is updated.
		return r, requeueWaitWhileDeleting
	}
	if isUpdating(r) {
		// Setting resource synced condition to false will trigger a requeue of
		// the resource.
		ackcondition.SetSynced(
			r,
			corev1.ConditionFalse,
			&condMsgNoDeleteWhileUpdating,
			nil,
		)
		// Need to return a requeue error here, otherwise:
		// - reconciler.deleteResource() marks the resource unmanaged
		// - reconciler.HandleReconcileError() does not update status for unmanaged resource
		// - reconciler.handleRequeues() is not invoked for delete code path.
		// TODO: return err as nil when reconciler is updated.
		return r, requeueWaitWhileUpdating
	}

	input, err := rm.newDeleteRequestPayload(r)
	if err != nil {
		return nil, err
	}
	var resp *svcsdk.DeleteClusterOutput
	_ = resp
	resp, err = rm.sdkapi.DeleteCluster(ctx, input)
	rm.metrics.RecordAPICall("DELETE", "DeleteCluster", err)
	// delete call successful
	if err == nil {
		rp, _ := rm.sdkFind(ctx, r)
		// Setting resource synced condition to false will trigger a requeue of
		// the resource.
		ackcondition.SetSynced(
			r,
			corev1.ConditionFalse,
			&condMsgCurrentlyDeleting,
			nil,
		)
		// Need to return a requeue error here, otherwise:
		// - reconciler.deleteResource() marks the resource unmanaged
		// - reconciler.HandleReconcileError() does not update status for unmanaged resource
		// - reconciler.handleRequeues() is not invoked for delete code path.
		// TODO: return err as nil when reconciler is updated.
		return rp, requeueWaitWhileDeleting
	}

	return nil, err
}

// newDeleteRequestPayload returns an SDK-specific struct for the HTTP request
// payload of the Delete API call for the resource
func (rm *resourceManager) newDeleteRequestPayload(
	r *resource,
) (*svcsdk.DeleteClusterInput, error) {
	res := &svcsdk.DeleteClusterInput{}

	if r.ko.Spec.Name != nil {
		res.ClusterName = r.ko.Spec.Name
	}
	if r.ko.Status.MultiRegionClusterName != nil {
		res.MultiRegionClusterName = r.ko.Status.MultiRegionClusterName
	}

	return res, nil
}

// setStatusDefaults sets default properties into supplied custom resource
func (rm *resourceManager) setStatusDefaults(
	ko *svcapitypes.Cluster,
) {
	if ko.Status.ACKResourceMetadata == nil {
		ko.Status.ACKResourceMetadata = &ackv1alpha1.ResourceMetadata{}
	}
	if ko.Status.ACKResourceMetadata.Region == nil {
		ko.Status.ACKResourceMetadata.Region = &rm.awsRegion
	}
	if ko.Status.ACKResourceMetadata.OwnerAccountID == nil {
		ko.Status.ACKResourceMetadata.OwnerAccountID = &rm.awsAccountID
	}
	if ko.Status.Conditions == nil {
		ko.Status.Conditions = []*ackv1alpha1.Condition{}
	}
}

// updateConditions returns updated resource, true; if conditions were updated
// else it returns nil, false
func (rm *resourceManager) updateConditions(
	r *resource,
	onSuccess bool,
	err error,
) (*resource, bool) {
	ko := r.ko.DeepCopy()
	rm.setStatusDefaults(ko)

	// Terminal condition
	var terminalCondition *ackv1alpha1.Condition = nil
	var recoverableCondition *ackv1alpha1.Condition = nil
	var syncCondition *ackv1alpha1.Condition = nil
	for _, condition := range ko.Status.Conditions {
		if condition.Type == ackv1alpha1.ConditionTypeTerminal {
			terminalCondition = condition
		}
		if condition.Type == ackv1alpha1.ConditionTypeRecoverable {
			recoverableCondition = condition
		}
		if condition.Type == ackv1alpha1.ConditionTypeResourceSynced {
			syncCondition = condition
		}
	}
	var termError *ackerr.TerminalError
	if rm.terminalAWSError(err) || err == ackerr.SecretTypeNotSupported || err == ackerr.SecretNotFound || errors.As(err, &termError) {
		if terminalCondition == nil {
			terminalCondition = &ackv1alpha1.Condition{
				Type: ackv1alpha1.ConditionTypeTerminal,
			}
			ko.Status.Conditions = append(ko.Status.Conditions, terminalCondition)
		}
		var errorMessage = ""
		if err == ackerr.SecretTypeNotSupported || err == ackerr.SecretNotFound || errors.As(err, &termError) {
			errorMessage = err.Error()
		} else {
			awsErr, _ := ackerr.AWSError(err)
			errorMessage = awsErr.Error()
		}
		terminalCondition.Status = corev1.ConditionTrue
		terminalCondition.Message = &errorMessage
	} else {
		// Clear the terminal condition if no longer present
		if terminalCondition != nil {
			terminalCondition.Status = corev1.ConditionFalse
			terminalCondition.Message = nil
		}
		// Handling Recoverable Conditions
		if err != nil {
			if recoverableCondition == nil {
				// Add a new Condition containing a non-terminal error
				recoverableCondition = &ackv1alpha1.Condition{
					Type: ackv1alpha1.ConditionTypeRecoverable,
				}
				ko.Status.Conditions = append(ko.Status.Conditions, recoverableCondition)
			}
			recoverableCondition.Status = corev1.ConditionTrue
			awsErr, _ := ackerr.AWSError(err)
			errorMessage := err.Error()
			if awsErr != nil {
				errorMessage = awsErr.Error()
			}
			recoverableCondition.Message = &errorMessage
		} else if recoverableCondition != nil {
			recoverableCondition.Status = corev1.ConditionFalse
			recoverableCondition.Message = nil
		}
	}
	// Required to avoid the "declared but not used" error in the default case
	_ = syncCondition
	if terminalCondition != nil || recoverableCondition != nil || syncCondition != nil {
		return &resource{ko}, true // updated
	}
	return nil, false // not updated
}

// terminalAWSError returns awserr, true; if the supplied error is an aws Error type
// and if the exception indicates that it is a Terminal exception
// 'Terminal' exception are specified in generator configuration
func (rm *resourceManager) terminalAWSError(err error) bool {
	if err == nil {
		return false
	}

	var terminalErr smithy.APIError
	if !errors.As(err, &terminalErr) {
		return false
	}
	switch terminalErr.ErrorCode() {
	case "ClusterAlreadyExistsFault",
		"InvalidParameterValueException",
		"InvalidParameterCombinationException",
		"NoOperationFault":
		return true
	default:
		return false
	}
}
